---
title: "Practical ML, Final Assignment"
author: "Mat Dac"
date: "December 17, 2017"
output: html_document
---

```{r markdown setup, include=F}
knitr::opts_chunk$set(include=T, echo=T, warning=F, message=F, cache=T)
setwd("~/Work/Training/PracticalMachineLearningCoursera.R")
```

## Load datasets

The following libraries are used for this project:

```{r setup}
library(data.table)
library(caret)
library(doMC)
registerDoMC(cores = 8)
```

## Load datasets

The data were loaded and the training set was split into a training (80%) and test set (20%). The test set will be used to estimate the out-of-sample error.

```{r load}
set.seed(3456)
TrainTestData = fread(file="pml-training.csv")
PredictData = fread(file="pml-testing.csv")
TrainTestData[, classe:=as.factor(classe)]
TrainIndex = createDataPartition(TrainTestData$classe, p = .8, list=T)[[1]]
TrainingData = TrainTestData[TrainIndex]
TestingData = TrainTestData[-TrainIndex]
```

## Prepare data

Many variables were encoded as character but were in fact numeric variables. Thus a large list of variables had to be converted to numeric. 

```{r to numeric}
CharNam = names(which(sapply(TrainingData, class)=="character"))
ToNum = c("kurtosis_roll_belt", "kurtosis_picth_belt", "kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt", "max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "kurtosis_roll_arm", "kurtosis_picth_arm", "kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm", "kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell", "skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell", "amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm", "skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_yaw_forearm", "min_yaw_forearm", "amplitude_yaw_forearm")
TrainingData[, (ToNum):=lapply(.SD, as.numeric), .SDcols=ToNum]
```
### Near zero variance

The nearZeroVar function of the caret packet was used to identified variables with problematic distributions.

```{r nzv}
nzv <- nearZeroVar(TrainingData, saveMetrics= TRUE)
NoZeroVarNam = row.names(nzv[nzv$nzv==F, ])
```

### Missing values

Variables with more than 90% of missing values was also removed from the analyses.

```{r missing values}
PctNa = TrainingData[, lapply(.SD, function (X) {round(100*sum(is.na(X))/length(X))})]
LowNaNam = names(PctNa)[as.numeric(PctNa)<90]
```

### Other variable exclusion

The outcome variable was removed from the input variables. Only the cvtd_timestamp variable was kept in the model while the other 2 time variables were removed because they were redudant.

```{r other exclusion}
ManualExcludeNam = c("V1", "classe", "raw_timestamp_part_1", "raw_timestamp_part_2")
InputTmp = setdiff(intersect(NoZeroVarNam, LowNaNam), ManualExcludeNam)
```

### Correlations

Three variables highly correlated with others variables (>.90) were removed to avoid multicolinarity.

```{r correlations}
NumericNam = names(which(sapply(TrainingData, class)=="numeric"))
InputTmp2 = intersect(InputTmp, NumericNam)
Cor = cor(TrainingData[, InputTmp2, with=F])
HighCorIdx = findCorrelation(Cor)
HighCorNam = colnames(Cor)[HighCorIdx]
```

The 3 variables with high correlation are: `r HighCorNam`.

## Define input and ouput variables

Here the input and output variables of the model were selected. Input variables with problematic distributions, many missing values or high correlations were removed. The model formula is given by:

```{r define in and out}
InputNam = setdiff(InputTmp, HighCorNam)
OutputNam = "classe"
rhs = paste(InputNam, collapse = " + ")
formulaTrain = as.formula(paste(OutputNam, rhs, sep=" ~ "))
formulaTrain
```

The number of input variables was `r length(InputNam)`.

## Plot class frequency

A barplot revealed that the outcome variable was almost evenly distributed.

```{r plot class}
ClassCount = table(TrainingData$classe, useNA="ifany") # no NA
barplot(ClassCount)
```

## Linear discriminant analysis

The first model trained was a linear discriminant analysis. It was chosen because it can predict more than 2 classes and is a fast algorithm. A 10 fold cross-validation was performed.

```{r train lda}
tc = trainControl(method="cv", number=10)
lda.fit = train(formulaTrain, data=TrainingData, method="lda", trControl=tc)
lda.fit
```

The out-of-sample accuracy was calculated on a separate test set and equals 0.85 (0.15 error rate). The confusion matrix on the test set is shown below:

```{r lda test error}
LdaPredTest = predict(lda.fit, newdata = TestingData)
cm = confusionMatrix(data=LdaPredTest, reference=TestingData$classe)
cm$table
```

## Random forest

The second model trained was a random forest. It was chosen because it generally offers a very good accuracy. A 10-fold cross validation was performed to estimate the hyper-parameter that controls the number of variables selected randomly at each tree iteration.

```{r train random forest}
tc = trainControl(method="cv", number=8)
grid = expand.grid(mtry = c(4, 6))
randomForest.fit = train(formulaTrain, data=TrainingData, method="rf", trControl=tc, tuneGrid=grid)
randomForest.fit
```

The cross-validation revealed that between 4 and 6, the best value of the hyper-parameter was 6. Here is the relative importance of the first 10 most important variables:

```{r importance random forest}
VarImp = varImp(randomForest.fit$finalModel)
VarImp = data.table(row.names(VarImp), VarImp[, 1])
VarImpOrder = VarImp[order(V2, decreasing=T),]
VarImpOrder$Order = 1:nrow(VarImpOrder)
ImpVarNam = VarImpOrder[1:10, V1]
ggplot(data=VarImpOrder[1:10], aes(x=reorder(V1, -Order, decreasing=F), y=V2)) + geom_bar(stat="identity") + labs(x = "Importance", y = "Variable") + coord_flip()
```

The out-of-sample accuracy was 0.998 (0.002 error rate) for the random forest and the confusion matrix is shown below:

```{r random forest test error}
RfPredTest = predict(randomForest.fit, newdata = TestingData)
cm = confusionMatrix(data=RfPredTest, reference=TestingData$classe)
cm$table # confusion matrix
```

The prediction for the 20 cases are listed below.

```{r random forest predict}
RfPred = predict(randomForest.fit, newdata = PredictData)
data.table(RfPred)
```

## Conclusion

The random forest gave a higer out-of-sample accuracy compared to the linear discriminant analysis and was thus the selected model to make the final prediction on the 20 cases.



