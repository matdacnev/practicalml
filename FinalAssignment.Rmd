---
title: "Practical ML, Final Assignment"
author: "Mat Dac"
date: "December 17, 2017"
output: html_document
---

```{r markdown setup, include=F}
knitr::opts_chunk$set(include=T, echo=T, warning=F, message=F, cache=T)
```


```{r setup, include=FALSE}
setwd("~/Work/Training/PracticalMachineLearningCoursera.R")
library(data.table)
library(caret)
library(doMC)
registerDoMC(cores = 8)
```

## Load datasets

The data were loaded and the training set was split into a training and test set. The test set will be used to estimate the out of sample error.

```{r load}
set.seed(3456)
TrainTestData = fread(file="pml-training.csv")
PredictData = fread(file="pml-testing.csv")
TrainTestData[, classe:=as.factor(classe)]
TrainIndex = createDataPartition(TrainTestData$classe, p = .8, list=T)[[1]]
TrainingData = TrainTestData[TrainIndex]
TestingData = TrainTestData[-TrainIndex]
```

## Prepare data

Many variable were encoded as character but were in fact numeric variables. Thus a large list of variables had to be converted to numeric. 

```{r to numeric}
CharNam = names(which(sapply(TrainingData, class)=="character"))
ToNum = c("kurtosis_roll_belt", "kurtosis_picth_belt", "kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt", "max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "kurtosis_roll_arm", "kurtosis_picth_arm", "kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm", "kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell", "skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell", "amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm", "skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_yaw_forearm", "min_yaw_forearm", "amplitude_yaw_forearm")
TrainingData[, (ToNum):=lapply(.SD, as.numeric), .SDcols=ToNum]
```
### Near zero variance

The nearZeroVar function of the caret packet was used to identified the variable with problematic distributions.

```{r nzv}
nzv <- nearZeroVar(TrainingData, saveMetrics= TRUE)
NoZeroVarNam = row.names(nzv[nzv$nzv==F, ])
```

### Missing values

A list of variables with more than 90% of missing values was also created for removal.

```{r missing values}
PctNa = TrainingData[, lapply(.SD, function (X) {round(100*sum(is.na(X))/length(X))})]
LowNaNam = names(PctNa)[as.numeric(PctNa)<90]
```

### Other variable exclusion

The outcome variable was removed from the list of input variables. For time measurement, only the cvtd_timestamp variable was kept in the model while the other two time variables were removed because they were redudant.

```{r other exclusion}
ManualExcludeNam = c("V1", "classe", "raw_timestamp_part_1", "raw_timestamp_part_2")
InputTmp = setdiff(intersect(NoZeroVarNam, LowNaNam), ManualExcludeNam)
```

### Correlations

Three variables highly correlated with others variables (>.90) were removed to avoid problems of multicolinarity.

```{r correlations}
NumericNam = names(which(sapply(TrainingData, class)=="numeric"))
InputTmp2 = intersect(InputTmp, NumericNam)
Cor = cor(TrainingData[, InputTmp2, with=F])
HighCorIdx = findCorrelation(Cor)
HighCorNam = colnames(Cor)[HighCorIdx]
```

The three variables with high correlation are: `r HighCorNam`.

## Define input and ouput variables

Here the input and output variables of the model were selected. Input variables with problematic distributions, many missing values or high correlations were removed.

```{r define in and out}
InputNam = setdiff(InputTmp, HighCorNam)
OutputNam = "classe"
rhs = paste(InputNam, collapse = " + ")
formulaTrain = as.formula(paste(OutputNam, rhs, sep=" ~ "))
```

The final number of input variables was `r length(InputNam)`.

## Plot class frequency

A barplot revealed that the 5 classes to predict were almost evenly distributed.

```{r plot class}
ClassCount = table(TrainingData$classe, useNA="ifany") # no NA
barplot(ClassCount)
```

## Linear discriminant analysis

The first model trained was a linear discriminant analysis. It was chosen because it can predict more than 2 classes and is a fast algorithm. A 10 fold cross-validation was performed.

```{r train lda}
tc = trainControl(method="cv", number=10)
lda.fit = train(formulaTrain, data=TrainingData, method="lda", trControl=tc)
lda.fit
```

The out-of-sample accuracy is 0.85 (0.15 error rate) and the confusion matrix is shown below:

```{r lda test error}
LdaPredTest = predict(lda.fit, newdata = TestingData)
cm = confusionMatrix(data=LdaPredTest, reference=TestingData$classe)
cm$table
```

The prediction for the 20 cases are listed below.

```{r lda predict}
LdaPred = predict(lda.fit, newdata = PredictData)
data.table(LdaPred)
```

## Random forest

The second model trained was a random forest. It was chosen because it generally offer a very good accuracy. A 10-fold cross validation was performed to estimate the hyperparameter that controls the number of variables selected randomly at each tree iteration.

```{r train random forest}
tc = trainControl(method="cv", number=8)
grid = expand.grid(mtry = c(4, 6))
randomForest.fit = train(formulaTrain, data=TrainingData, method="rf", trControl=tc, tuneGrid=grid)
randomForest.fit
```

 The cross-validation reveased that between 4 and 6, 6 was the best value of the hyper-parameter. Here is the relative importance of the first 10 most important variables:

```{r importance random forest}
VarImp = varImp(randomForest.fit$finalModel)
VarImp = data.table(row.names(VarImp), VarImp[, 1])
VarImpOrder = VarImp[order(V2, decreasing=T),]
VarImpOrder$Order = 1:nrow(VarImpOrder)
ImpVarNam = VarImpOrder[1:10, V1]
ggplot(data=VarImpOrder[1:10], aes(x=reorder(V1, -Order, decreasing=F), y=V2)) + geom_bar(stat="identity") + coord_flip()
```

The out-of-sample accuracy is 0.998 (0.002 error rate) and the confusion matrix is shown below:

```{r random forest test error}
RfPredTest = predict(randomForest.fit, newdata = TestingData)
cm = confusionMatrix(data=RfPredTest, reference=TestingData$classe) # accuracy=0.9977, Kappa=0.9977
cm$table # confusion matrix
```

The prediction for the 20 cases are listed below.

```{r random forest predict}
RfPred = predict(randomForest.fit, newdata = PredictData)
data.table(RfPred)
```

## Conclusion

The random forest gave a higer out-of-sample accuracy compared to linear discriminant analysis.



